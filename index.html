<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Course Project
  | ECE, Virginia Tech | Fall 2021: ECE 4554/5554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Lane Detection System For ADAS Using Computer Vision and Deep Learning</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Krishna Kanth Vuppala Narasimha, Beenaa Motiram Salian, Sriamoghavarsha Beerangi Srinivasa</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2023 ECE 4554/5554 Computer Vision: Course Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
<hr>

<!-- Goal -->
<h3>Abstract</h3>

With the increasing demand for safer and more efficient autonomous driving, our project tackles the crucial task of enhancing lane detection systems. Accurate lane detection is pivotal for safe navigation and has far-reaching implications for the future of self-driving vehicles. We adopted a comprehensive approach by implementing and comparing two advanced deep learning models, LaneNet and SegNet, both trained on a diverse dataset of highway images. Our evaluation, conducted within the Carla Simulator, aimed to provide insights into the models' performance in real-world driving scenarios
<br><br>

<!-- figure -->
<!-- Main Illustrative Figure --> 
<h3>Teaser figure</h3>
<br><br>
<div style="text-align: center;">
<img style="height: 150px;" alt="Teaser Image" src="teaser_img.png">
</div>
<br><br>
<div style="text-align: center;">
<img style="height: 200px;" alt="Teaser Image" src="https://thegradient.pub/content/images/2018/05/semseg.gif">
</div>
<br><br>

<!-- Introduction -->
<h3>Introduction</h3>
The quest for achieving precision and reliability in lane detection has been a focal point in the world of autonomous vehicles and advanced driving assistance systems. Ensuring accurate lane detection is crucial for vehicle safety, facilitating tasks like lane-keeping and path planning, especially in intricate urban environments. Traditional computer vision methods, though pioneering, often falter when confronted with real-world challenges, such as faded lane markings, unpredictable shadows, or adverse weather conditions.
<br><br>
In the deep learning realm, models like LaneNet and SegNet have emerged as potential game-changers for lane detection. LaneNet, with its emphasis on semantic and instance segmentation, is adept at distinguishing overlapping lanes, adapting effectively to intricate road scenarios. In contrast, SegNet, drawing inspiration from the VGG16 architecture, is renowned for its semantic segmentation capabilities, offering pixel-wise classification that is crucial for clear lane boundary identification in varied contexts. Both models, tailored for regular RGB photographs, address many of the limitations intrinsic to conventional methods.
<br><br>
In this project, rather than merging their capabilities, we endeavor to conduct a comprehensive comparison between LaneNet and SegNet. By evaluating their strengths and potential pitfalls in the domain of lane detection, we aim to provide insights that might guide future advancements in the field, determining which approach offers the most promise in real-world driving scenarios.
<br><br>
<!-- Approach -->
<h3>Approach</h3>
Describe very clearly and systematically your approach to solve the problem. Tell us exactly what existing implementations you used to build your system. Tell us what obstacles you faced and how you addressed them. Justify any design choices or judgment calls you made in your approach.

<br><br>
<!-- Results -->
<h3>Experimental Setup</h3>
Provide details about the experimental set up (number of images/videos, number of datasets you experimented with, train/test split if you used machine learning algorithms, etc.). Describe the evaluation metrics you used to evaluate how well your approach is working. Include clear figures and tables, as well as illustrative qualitative examples if appropriate. Be sure to include obvious baselines to see if your approach is doing better than a naive approach (e.g. for classification accuracy, how well would a classifier do that made random decisions?). Also discuss any parameters of your algorithms, and tell us how you set the values of those parameters. You can also show us how the performance varies as you change those parameter values. Be sure to discuss any trends you see in your results, and explain why these trends make sense. Are the results as expected? Why?

<br><br>

<!-- Results -->
<h3>Expected Outcomes</h3>
The anticipated outcomes of this study encompass several key aspects. 
We expect to achieve a high level of accuracy in lane detection for both LaneNet and SegNet, with well-balanced precision and recall scores. 
Additionally, a comparative analysis is likely to reveal nuanced strengths, where LaneNet may excel in intricate lane markings, while SegNet might demonstrate superior performance in complex, diverse environments. We foresee robust adaptability across various lighting conditions and road types, including highways, urban streets, and rural roads. 
Visual representations will provide clear illustrations of lane detection outputs, aiding in the assessment of model performance. Moreover, insights into potential areas for improvement, such as hyperparameter fine-tuning and enhanced data augmentation, are expected. 
<br><br>


<!-- References -->
<h3>References</h3>
<ul>
  <li><a href="https://arxiv.org/abs/1807.01726">[1] LaneNet: Real-Time Lane Detection Networks for Autonomous Driving</a></li>
  <li><a href="https://arxiv.org/abs/1511.00561">[2] SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</a>
  <li><a href="https://carla.org/">[3] CARLA: Open-source simulator for autonomous driving research</a>
  </ul>
<br><br>


  <hr>
  <footer> 
  <p>Â© Krishna Kanth Vuppala Narasimha, Beenaa Motiram Salian, Sriamoghavarsha Beerangi Srinivasa</p>
  </footer>
</div>
</div>

<br><br>

</body></html>